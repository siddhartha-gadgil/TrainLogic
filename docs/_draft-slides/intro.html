---
title: Introduction and Set Theory
date: 31 July 2019
--- 
<section>
    <h3>Course of Lectures on</h3>
    <ul>
        <li>First-order logic</li>
        <li>Set Theory</li>
        <li>$\lambda$-calculus</li>
        <li>Type Theory</li>
    </ul>
    <p> <a href="{{ site.baseurl}}/index.html" target="_blank">https://siddhartha-gadgil.github.io/TrainLogic/</a> </p>
</section>

<section>
    <section>
        <h2>Formal Methods</h2>
        <p>Mathematical proofs checked by computers.</p>
    </section>
    <section>
        <h3>The Pentium FDIV bug</h3>
        <ul>
            <li class="fragment">
                    Thomas Nicely, a professor of mathematics at Lynchburg College, had written code to enumerate primes, 
                    twin primes, prime triplets, and prime quadruplets.
            </li>
            <li class="fragment">
                    Nicely noticed some inconsistencies in the calculations shortly after adding a Pentium system to his group of computers</li>
                    <li class="fragment">
                    After eliminating other factors he reported the issue to Intel.
            </li>
        </ul>
    </section>
    <section>
            <ul>
                <li> This was a bug in the pentium chip due to missing entries in the lookup table used by the floating-point division circuitry.</li>
                <li class="fragment"> This bug had escaped testing. </li>
                <li class="fragment">
                        This caused Intel to take a $475M charge against earnings and management "don't ever let this happen again".
                </li>
                <li class="fragment"> In 1996 they started proving properties of the Pentium processor FPU.</li>
               
            </ul>
    </section>
    <section>
        <ul>
                <li> Then in 1997 a bug was discovered in the FIST instruction (that converts floating point numbers to integers) 
                    in the formally verified correct Pentium Pro FPU.</li>
                <li class="fragment">  It was a protocol mismatch between two blocks not accounted for in the informal arguments. </li>
                <li class="fragment">So they went back to square one and during 1997-98 the verified the entire FPU against high-level specs 
                    so that mismatches like the FIST bug could no longer escape. </li>
                <li class="fragment">During 1997-99 the Pentium 4 processor was verified and there were no escapes.</li>
        </ul>
    </section>
    <section>
        <h3>TimSort</h3>
        <ul>
            <li class="fragment">Tim Peters developed the Timsort hybrid sorting algorithm in 2002 - this is the standard sorting algorithm in Java, Android, Python etc.</li>
            <li class="fragment">It is a clever combination of ideas from merge sort and insertion sort, and designed to perform well on real world data.</li>
            <li class="fragment">Specifically, data is grouped into <em>runs</em>, sequences that are already ordered, using <em>insertion sort</em> if needed. 
                Runs are merged as in <em>merge sort</em>.</li>
            <li class="fragment">Run lengths are stored on a stack, which should be small for performance reasons.</li>
        </ul>
    </section>
    <section>
        <ul>
            <li> After having successfully verified Counting and Radix sort implementations in Java, the Dutch-German <em>Envisage</em> group 
                turned to proving the correctness of TimSort.</li>
            <li class="fragment"> After struggling to prove this, they realized they could not because the implementation was in fact wrong.</li>
            <li class="fragment"> Specifically the size of the stack for run lengths was estimated based on a (growth) property of run lengths, but this did not always hold.</li>
            <li class="fragment"> They proved that a modified version of the property holds, and a corresponding algorithm does work.</li>
        </ul>
    </section>
    <section>
        <h3>Conclusions from TimSort</h3>
        <ul>
            <li class="fragment">Formal methods are often classified as irrelevant and/or impracticable by practitioners. 
                This is not true: the researchers found and fixed a bug in a piece of software that is used by billions of users every single day.</li>
            <li class="fragment">Even though the bug itself is unlikely to occur, it is easy to see how it could be used in an attack.</li>
        </ul>
    </section>
    <section>
        <h3>Using Formal methods</h3>
        <ul>
            <li class="fragment">Formal methods are mathematical proofs checked by computers.</li>
            <li class="fragment">What are mathematical proofs?</li>
            <li class="fragment">How do we know that the program checking the proof is correct?</li>
            <li class="fragment">Why does everyone not do so already?</li>
        </ul>
        
    </section>
    <section>
        <h3>Why not always?</h3>
        <ul>
            <li class="fragment">Formal proving takes work, so we have a trade-off between <em>productivity</em> and <em>safety</em>.</li>
            <li class="fragment">We have the same trade-off between dynamic and static typing; and often productivity wins.</li>
            <li class="fragment">Better languages and tooling can help in getting safety without losing too much productivity.</li>
        </ul>
    </section>
    <section>
        <h3>Who guards the guards?</h3>
        <ul>
            <li class="fragment">Formal proof systems have a small <em>trusted kernel</em>.</li>
            <li class="fragment">All proofs are verified, directly or indirectly, by the kernel.</li>
            <li class="fragment">The trusted kernel itself should be checked independently and thoroughly several times.</li>
            <li class="fragment">For example, <em>lean theorem prover</em> has independent type checkers (i.e. kernels) in three languages.</li>
        </ul>
        
    </section>
    <section>
        <h3>Foundations: Logic, Sets, Types</h3>
        <ul>
            <li class="fragment">
                The usual foundations of mathematics are <em>Set Theory</em> as a theory in <em>First-order logic</em>. 
            </li>
            <li class="fragment"> Computation can be founded on $\lambda$-calculus or two other <em>equivalent</em> models.</li>
            <li class="fragment"> <em>Type theory</em> gives common foundations integrating proofs and computations.</li>
            <li class="fragment"> All these are based on <em>capabilities</em> to perform basic operation 
                such as pattern matching on strings; and <em>agreement</em> on the meanings of such operations.</li>
        </ul>
    </section>
</section>
<section>
    <section>
        <h2>Foundations</h2>
        <h3>of</h3>
        <h2>Mathematics (and Computation)</h2>
    </section>
    <section>
        <ul>
            <li>
                Decide whether the following are true or false.
                <ul>
                    <li class="fragment">$2 < 3$</li>
                    <li class="fragment">$ 3 > 4$</li>
                    <li class="fragment"> $3 + 12$</li>
                    <li class="fragment"> $3 += 4++ $</li>
                </ul>
            </li>
            <li class="fragment"> 
                We can only ask whether an expression is true or false provided:
                <ul>
                    <li class="fragment"> It is a <em>well-formed</em> (meaningful) expression.</li>
                    <li class="fragment"> It represents a <em>statement</em> (not an object such as a number or set).</li>
                </ul>
            </li>
        </ul>
    </section>
    <section>
        <h3>Layers of foundations</h3>
        <ul>
            <li class="fragment"> A <em>language</em>, given by rules of its grammar/syntax, that specifies well-formed expressions 
                as well as <em>types</em> of these expressions.</li>
            <li class="fragment"> Rules of <em>deduction</em> letting us conclude that a statement is true from other true statements.</li>
            <li class="fragment"> <em>Axioms</em>: statements that are known to be true. </li>
            <li class="fragment"> Rules are <em>syntactic</em> in nature, i.e., in terms of manipulating and pattern matching strings, 
            </li>
            <li class="fragment">Rules can be computed quickly.</li>
        </ul>
    </section>
    <section>
        <h3>Generative grammars</h3>
        <ul>
            <li class="fragment">The languages we consider are given by
                <ul>
                    <li class="fragment">an initial vocabulary of expressions (with types),</li>
                    <li class="fragment">(introduction) rules to form new expressions from existing ones and assigning types to these,</li>
                    <li class="fragment">such that the rules depend only on the types of the expressions.</li>
                </ul>
            </li>
            <li class="fragment">Well-formed expressions are exactly those that can be formed from the vocabulary using the introduction rules.</li>
            <li class="fragment">We can prove properties of such expressions by induction.</li>
        </ul>
    </section>
    <section>
        <h3>Natural and programming languages</h3>
        <ul>
            <li class="fragment"> For example in English
                <ul>
                    <li class="fragment">The vocabulary has nouns, verbs, adjectives etc.</li>
                    <li class="fragment">A single noun forms a noun phrase, e.g. <code>lecture</code>.</li>
                    <li class="fragment">An adjective followed by a noun phrase forms a noun phrase, e.g. <code>boring lecture</code>.</li>
                </ul>
            </li>
            <li class="fragment"> Similarly, in most programming languages if <code>x</code> and <code>y</code> are expressions 
                with type <code>Int</code>, we can form the expression <code>x + y</code> of type <code>Int</code>.</li>
            <li class="fragment"> We can also form the <code>Boolean</code> expression <code>x < y</code>.</li>
            
        </ul>
    </section>
    <section>
        <ul>
            <li> Thus, mathematical expressions and their types are determined by the syntax of a generative language.</li>
            <li class="fragment"> In particular, it is straightforward to generate all expressions, and to check the validity and type of an expression.</li>
            <li class="fragment"> Similarly valid deductions are those given by repeated application of syntactic rules.</li>
            <li class="fragment"> For example, the rule <em>Modus Ponens</em> says that for formulas $P$ and $Q$, from $P$ and $P \implies Q$ we can deduce $Q$.</li>
            <li class="fragment"> A specific class of such languages and rules of deduction constitute <em>First-order logic</em>, 
                on which the usual foundations of mathematics are based.</li>
        </ul>
    </section>
    <section>
        <h3>Theories and Sets</h3>
        <ul>
            <li class="fragment"> A <em>theory</em> is a (first-order) language together with a collection of axioms, i.e., statements that are taken to be true.</li>
            <li class="fragment"> A specific first-order language and set of axioms constitute Set Theory.</li>
            <li class="fragment"> All of mathematics can be encoded in terms of Set Theory. However this is verbose and opaque, like Bytecode/assembly language .</li>
            <li class="fragment"> Hence any practical formalization depends on using some combination of a proof assistant and more expressive foundations.</li>
        </ul>
    </section>
    <section>
        <h3>Verification in the real world</h3>
        <ul>
            <li class="fragment">The real-world problem needs to be (correctly) modelled mathematically/logically.</li>
            <li class="fragment">The mathematical model needs to be (correctly) embedded in Set theory or other appropriate foundations.</li>
            <li class="fragment">By results of logic, statements that are <em>deduced</em> following the rules of syntax are <em>true</em> in the Set Theoretic model.</li>
        </ul>
    </section>
</section>
<section>
    <section>
        <h2>First-order Languages</h2>
    </section>
    <section>
        <h3>Data for a language</h3>
        <ul>
            <li class="fragment">
                First-order languages (e.g. Arithmetic, Sets) are specified by (possibly empty) lists of
                <ul>
                    <li class="fragment">(names of) constants, e.g. $0$, $1$, $\phi$.</li>
                    <li class="fragment">(names of) functions together with their degree/arities, e.g., <em>addition</em> ($+$) with degree $2$.</li>
                    <li class="fragment">(names of) relations together with their degree/arities, e.g.,
                         <em>less than</em> ($<$) and <em>belongs to</em> ($\in$) with degree $2$.</li>
                    <li class="fragment">(names of) variables - these can be assumed to be independent of the language.</li>
                </ul>
            </li>
        </ul>
    </section>
    <section>
        <h3>Expressions</h3>
        <ul>
                <li class="fragment">We form two types of expressions:
                        <ul>
                            <li class="fragment"> <em>Terms:</em> representing numbers, sets etc.</li>
                            <li class="fragment"> <em>Formulas:</em> representing properties of numbers, sets, etc. </li>
                        </ul>     
                    </li>
                <li class="fragment">Both terms and formulas may depend on variables.</li>
        </ul>
    </section>
    <section>
        <h3>Terms</h3>
        
        <ul>Terms are expressions recursively given by the rules
            <li class="fragment">A variable $x$ is a term.</li>
            <li class="fragment">A constant $c$ is a term.</li>
            <li class="fragment"> If $f$ is a function of degree $n$ and $t_1$, $t_2$, $\dots$, $t_n$ are terms then $f(t_1, t_2,\dots,t_n)$ is a term.</li>
        </ul>
    </section>
    <section>
            <h3>Formulas</h3>
            
            <ul>Formulas are expressions recursively given by the rules
                <li class="fragment"> If $p$ is a relation of degree $n$ and $t_1$, $t_2$, $\dots$, $t_n$ are terms then $p(t_1, t_2,\dots,t_n)$ is a term.</li>
                <li class="fragment"> If $P$ and $Q$ are formulas then $P\wedge Q$, $P\vee Q$,  $P\implies Q$, $P\iff Q$, and $\neg P$ are formulas. </li>
                <li class="fragment"> If $P$ is a formula and $x$ is a variable, then $\forall x P$ and $\exists x P$ are formulas.</li>
                <li class="fragment"> We recursively define <em>free variables</em> of terms and formulas. A formula is <em>closed</em> if it has no free variables.</li>
            </ul>
        </section>
    
</section>
<section>
        <section>
                <h2>Set Theory</h2>
            </section>
            <section>
                <h3>Sets as collections</h3>
                <ul>
                    <li class="fragment"> A <em>Set</em> $S$ is a collection of objects, with no other structure.</li>
                    <li class="fragment"> Thus, we have a relation $x \in S$, for any object $x$, corresponding to $x$ being a member of $S$.</li>
                    <li class="fragment"> Further, if $S$ and $T$ are sets with the <em>same</em> members they are equal, i.e. if 
                        $$\forall x\ x\in S \iff x\in T$$
                        then $S= T$ <strong>(Axiom of extension)</strong>.
                     </li>
                </ul>
            </section>
            <section>
                <h3>What collections?</h3>
                <ul>
                    <li class="fragment"> We need some way to construct sets.</li>
                    <li class="fragment"> A natural way to try to do this is to say sets are collections of objects that satisfy some <em>property</em>, e.g. 
                     $$\{p: \text{$p$ is a prime number} \}.$$ </li>
                    <li class="fragment"> We can make this formal by defining properties to be <em>closed formulas</em> in some first-order language 
                        (or in the first-order language of sets).</li>
                </ul>
            </section>
            <section>
                <h3>Russell's Paradox</h3>
                <ul>
                    <li class="fragment">Assume we had sets corresponding to all closed formulas in the first-order language of sets.</li>
                    <li class="fragment"> Consider the set 
                        $$ S = \{X : X \notin X\}.$$ </li>
                    <li class="fragment"><strong>Question:</strong> Is $S\in S$?</li>
                    <li class="fragment">
                        We see that
                        <ul>
                            <li class="fragment"> if $S \notin S$ then $S \in S$,</li>
                            <li class="fragment"> if $S\in S$ then $S \notin S$.</li>
                        </ul>
                    </li>
                </ul>
            </section>
            <section>
                <h3>Sets from Axioms</h3>
                <ul>
                    <li class="fragment"> The <em>axiom of specification</em> allows us to define <em>subsets</em> of a set by a property.</li>
                    <li class="fragment"> Thus, if we have previously defined the natural numbers $\mathbb{N}$, then we can define the set
                            $$\{p: \text{$p$ is a prime number} \}.$$ 
                    </li>
                    <li class="fragment"> All axioms of set theory except <em>extension</em> are statements giving us the existence of sets.</li>
                    <li class="fragment"> The simplest of these is: "there exists a set"! </li>
                </ul>
            </section>
</section>