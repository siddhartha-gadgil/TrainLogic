---
title: Automating Mathematics?
date: July 7, 2019
---
<section>
	<h2> Automating Mathematics? </h2>
	<h2>Siddhartha Gadgil</h2>
	 <p>Department of Mathematics</p>
	 <p>Indian Institute of Science</p>
	 <p>Bangalore</p>
	 <p><a href="https://github.com/siddhartha-gadgil/ProvingGround" target="_blank">https://github.com/siddhartha-gadgil/ProvingGround</a></p>

</section>

<section>
		<section>
			<h3> Intelligence and Games </h3>
			<p> Tic-tac-toe </p>
			<p> Othello </p>
			<p> Deep Blue </p>
			<p> Alpha Go </p>
		</section>

		<section>
			<h3>Levels of intelligence</h3>
			<ul>
				<li class="fragment"> Carrying out specific computations and control functions.</li>
				<li class="fragment"> Following precise instructions to carry out arbitrary computations,
					i.e., to be computationally universal.</li>
				<li class="fragment"> Learning from experience, by imitation and by experimentation to get better results.</li>
				<li class="fragment"> Computers are  used today in mathematics as assistants, not collaborators.</li>
			</ul>
		</section>

		<section>
			<h3> Games and Strategies </h3>
			<ul>
				<li class="fragment">A game has:
					<ul>
						<li class="fragment">A <em>state</em> at any time.</li>
						<li class="fragment">Rules for making moves.</li>
						<li class="fragment">An outcome: win/loss, margin etc.</li>
					</ul>
				</li>
				<li class="fragment"> A strategy can be based on:
					<ul>
						<li class="fragment">A <em>policy</em> function, giving (weighted) moves to consider.</li>
						<li class="fragment">A  (relative) <em>value</em> function, telling us how good a state is.</li>
					</ul>
				</li>
				<li class="fragment"> We consider certain sequences of moves, based on policy, and optimize value at the end of the sequence.</li>
				<li class="fragment">In tic-tac-toe we can use  simple policies and values.</li>
				<li class="fragment">In Othello, we can refine the obvious value - number of black/white coins, by considering edges and corners.</li>
			</ul>
		</section>
		<section>
			<h3>Chess, Expert systems and  Deep Blue</h3>
				<ul>
					<li class="fragment">In Chess, a basic value function is obtained by counting pieces and pawns with weights.</li>
					<li class="fragment">For openings, we also have strict policy functions -
						we only consider a small subset of possible move sequences.</li>
					<li class="fragment"> Deep Blue (and chess theory) greatly extend these.</li>
					<li class="fragment"> The value and policy functions of Kasparov were far better, but compensated for by Deep Blue being able to consider far more move sequences.</li>
					<li class="fragment"> &ldquo; Play the opening like a book, the middle game like a magician, and the endgame like a machine.  &rdquo; – Spielmann</li>
					<li class="fragment"> A lesson from machines.</li>
				</ul>

		</section>
		<section>
			<h3>AlphaGo vs Lee Sedol</h3>
			<img src="./220px-Go-board-animated.gif" style="float: right">
				<ul style="width: 70%">
					<li class="fragment"> In Go, the  number of legal moves is much larger, causing the number of sequences for a weak policy to grow very fast.</li>
					<li class="fragment"> More importantly, it is very hard to describe a good value function.</li>
					<li class="fragment"> This makes it far harder for computers.</li>
					<li class="fragment"> Yet, in March 2016, a Go playing system AlphaGo defeated 18-time world champion Lee Sedol.</li>

				</ul>
		</section>
		<section>
			<h3>AlphaGo, Learning, Deep Neural Nets</h3>
			<ul>
				<li class="fragment"> The policy and value functions of AlphaGo are deep neural networks that were trained.</li>
				<li class="fragment"> The policy network was trained by learning to predict the next move from games of expert players.</li>
				<li class="fragment"> The value network was trained by AlphaGo playing against versions of itself and getting feedback from the outcome.</li>
				<li class="fragment"> AlphaGo considered fewer sequences of moves than Deep Blue.</li>
				<li class="fragment"> AlphaGo came up with unexpected moves.</li>
			</ul>
		</section>

		<section>
			<h3>Deep Neural Network</h3>
				<ul>
					<li class="fragment"> The state can be represented by a vector, on which we wish to find good functions. </li>
					<li class="fragment"> We first define a new vector in terms of the input vector as a composition of functions from vectors to vectors. Our desired functions are in terms of this new vector.</li>
					<li class="fragment"> We can view co-ordinates of vectors as forming layers, with each layer defined as a function of the previous layer.</li>
					<li class="fragment"> Each co-ordinate of a layer is a linear combination of (some of the) coordinates of the previous layer composed by a cut-off function.</li>
					<li class="fragment"> This can be trained by gradient flow, using the chain rule to backward propagate gradients.</li>
				</ul>
		</section>

		<section>
			<h3>Deep Learning and Science</h3>
				<ul>
					<li class="fragment"> We are trying to solve an Engineering problem of finding a near-optimal strategy, and the related scientific problem of understanding the strategy used by the brain (say for vision).</li>
					<li class="fragment"> A good scientific theory gives a concise description of (properties of) observations, which are good approximations.</li>
					<li class="fragment"> However, any reasonably concise description may give a very poor approximation, and near-optimal solutions may be far from unique.</li>
					<li class="fragment"> Yet, AlphaGo is not based on a single strategy network, but on two black-box networks and some concrete descriptions.</li>
				</ul>
		</section>
</section>



<section>
	<section>
		<h3>Theorem Proving:</h3>
		<h3> Enumeration, Computation, Deduction </h3>
		<p>Goals</p>
		<p>Computer-Assisted proof components</p>
		<p>Automated Deduction</p>
		<p> Limits of Set theory and First-order Logic</p>
	</section>
	<section>
		<h3> Goals </h3>
		<ul>
			<li><b> Goal:</b> Use computers to greatly increase our ability to discover and prove
				mathematical results across areas of mathematics.</li>
			<li class="fragment"> Why? </li>
			<li class="fragment"> How?
				<span class=fragment> <em>Learn</em> to <em>search</em> for, <em>construct</em> and <em>recognize</em> useful mathematical objects.
				</span>
			</li>
		</section>
		<section>
			<h3> What? </h3>
			<ul>
				<li class="fragment"> There are infinitely many prime numbers. </li>
				<li class="fragment"> There are arbitrarily long arithmetic progressions all of whose elements are prime numbers. </li>
				<li class="fragment"> There are infinitely many natural numbers $n$ such $n$ and $n+2$ are both primes.</li>
			</ul>
		</section>
	<section>
		<h3> Computer-Assisted proof components </h3>
		<ul>
			<li class="fragment"> Computers have been used in various ways to provide a <em>component</em> of a proof:
				<ul>
					<li> Enumeration, </li>
					<li> Symbolic algebra, </li>
					<li> Exact real number arithmetic, </li>
					<li> Linear programming, </li>
					<li> SAT solvers.</li>
				</ul>
			</li>

			<li class="fragment"> Some examples:
				<ul>
					<li> Four colour theorem, </li>
					<li> Kepler conjecture, </li>
					<li> Boolean Pythagorean triples problem. </li>
				</ul>
			</li>
		</ul>

	</section>

	<section>
		<h3>Formal proofs in Mathematics.</h3>
			<ul>
				<li class="fragment"> A formal deduction system should giver rules that describe
					<ul>
						<li class="fragment"> What are well-formed expressions, i.e., represent mathematical objects.</li>
						<li class="fragment"> How to deduce statements from other statements (more generally to make judgements).</li>
						<li class="fragment"> Axioms, which are well-formed propositions that we take to be proved.</li>
					</ul>
				</li>
				<li class="fragment"> In the usual foundations of mathematics, the rules for forming expressions and making deductions are those of First-Order Logic, and the axioms are those of Set Theory.</li>
			</ul>
	</section>


	<section>
	  <h3> First-order logic: languages</h3>
	  <ul>
	  <li class="fragment"> A first-order language, which describes a domain of discourse (e.g. $\mathbb{N}$) has vocabulary consisting of
	    <ul>
	      <li> Variables - can be taken to be a fixed countable set.</li>
	      <li> Constants (e.g. $0$, $1$).</li>
	      <li> Functions  (e.g. $+$).</li>
	      <li> Relations (e.g. $<$, $=$).</li>
	      <li> Special symbols $\Rightarrow$, $\iff$, $\wedge$, $\vee$, $\forall$, $\exists$, ... </li>
	      </ul>
	    <li class="fragment"> We form two kinds of expressions from these, <em>terms</em> (e.g. $1+1$, $n + 3$)
				and <em> formulas</em> (e.g. $n + 1 < 2$, $4 < 3$).</li>
	    <li class="fragment"> Terms and formulas may depend on variables.</li>
	    <li class="fragment"> Terms represent objects in the <em> domain of discourse</em>. </li>
	    <li class="fragment"> Formulas are either <em>true</em> or <em>false</em>. </li>
	    </ul>
	</section>

	<section>
	  <h3> Deduction and theories </h3>
	  <ul>
	    <li class="fragment"> We can deduce formulas from other formulas using the rules of deduction. </li>
	    <li class="fragment"> The main deduction rule is <em> Modus Ponens</em> : given $P$ and $P\Rightarrow Q$ we deduce $Q$.</li>
	    <li class="fragment"> A <em> theory</em> is a language together with a collection of formulas, called <em> axioms</em> in the language.</li>
	    <li class="fragment"> A formula is <em> deducible</em> in a theory if it can be
				obtained from the axioms by the rules of deduction.</li>
	  </ul>
	</section>

	<section>
		<h3> Universal deducer? </h3>
		<ul>
			<li class ="fragment"> A universal deducer is a computable function (algorithm) which, given a proposition (formula),
				returns a proof if it is deducible and otherwise returns failure.</li>
			<li class="fragment"> By results of Turing, there is no such algorithm. </li>
			<li class="fragment"> We can enumerate proofs and check if they prove either the given proposition or its negation.
				<span class="fragment"> This does not always work as there are statements that are true but not provable.</span>
			</li>
			 <li class="fragment"> Practically, we can conclude that there is no best deducer,
				 as any given proof can be found by some deducer but no deducer can find all proofs. </li>
		</ul>
	</section>


	<section>
		<h3> Robbins conjecture </h3>
		<ul>
			<li class="fragment"> Robbins conjecture was a conjectural characterization of Boolean algebras in terms of
				associativity and commutativity of $\vee$ and the Robbins equation
				$\neg(\neg(a\vee b)\vee \neg(a \vee \neg b)) = a$.</li>
			<li class="fragment"> This was conjectured in the 1930s, and finally proved in 1996 using the
				automated theorem prover EQP, which is a Resolution Theorem Prover with Paramodulation.</li>
			<li class="fragment"> So far, this seems to be the only major success of deductive theorem provers.</li>
			<li class="fragment"> First-order logic theorem provers are, however, used in interactive proof systems
				(hammer tactics). </li>
	</section>

	<section>
		<h3> Real-life mathematics</h3>
		<ul>
			<li class="fragment"> A proof in real-life mathematics consists of:
				<ul>
					<li class="fragment"> definitions, axioms, assumptions, notation; </li>
					<li class="fragment"> assertions; </li>
					<li class="fragment"> hints about which assertions, definitions etc. are used in the proof of a given assertion.</li>
					<li class="fragment"> focussing attention on relevant objects and results.</li>
					<li class="fragment"> introducing variables,hypotheses etc. into a scope.</li>
				</ul>
			</li>
			<li class="fragment"> The reader is expected to deduce all assertions based on the hints
				(or at least believe that he/she can do so).</li>
			<li class="fragment"> In particular, there is no objective sense in which a proof is complete or correct.</li>
			<!-- <li class="fragment"> Interactive proof systems modelled on human proofs, such as Mizar and Naproche,
				follow a similar approach.</li> -->
			</ul>
	</section>

	<section>
	  <p>
	    &ldquo; Since the first half of the 20th century mathematics has been presented as a science based on
	    ZFC and ZFC was introduced as a particular theory in Predicate Logic.
	  </p>
	  <p>
	    &ldquo; Therefore someone who wanted to get to the bottom of things in mathematics had a simple
	    road to follow - learn what Predicate Logic is, then learn a particular theory called ZFC, then
	    learn how to translate propositions about a few basic mathematical concepts into formulas of
	    ZFC, and then <span class="fragment highlight-red"> learn to believe, through examples, that the rest of mathematics can be reduced
	    to these few basic concepts</span>.&rdquo;</p>
<div style="text-align:right">Vladimir Voevodsky</div>
	  </section>

		<section>
<embed src="./Mochizuki.pdf" type="application/pdf" width="1000" height="650"> </embed>

		</section>

		<section>
<embed src="Sela.pdf" type="application/pdf" width="100%" height="650"> </embed>

		</section>

		<section>
<embed src="Verjovsky.pdf" type="application/pdf" width="100%" height="650"> </embed>

		</section>


	<section>
		<h3> Why better (new) foundations? </h3>
		<ul>
			<li class="fragment"> In the usual foundations of mathematics, $sin(3)$ and $3(sin)$ are syntactically equally valid, i.e., the usual language of mathematics is an informal language.
			</li>
			<li class="fragment"> Statements and proofs formalized in first-order logic are verbose and opaque.</li>
			<li class="fragment"> Propositions and Proofs are not first class, i.e., cannot be arguments or values of functions, so not composable.
 We instead have patterns of proof (such as induction).</li>
 			<li class="fragment"> HoTT foundations are fully formal, yet much closer to working mathematics and with a syntax that actually describes valid objects. Further, introducing variables, hypothesis and assumptions as well as inductive proofs, are natural.</li>
			</ul>
	</section>

	<section>
<p>
<q> &ldquo; The roadblock that prevented generations of interested mathematicians and computer scientists
from solving the problem of computer verification of mathematical reasoning was the
unpreparedness of foundations of mathematics for the requirements of this task.&rdquo;</q></p>
<p>
<q> &ldquo; Formulating mathematical reasoning in a language <span style="color:green">precise enough for a computer to follow</span>
meant using a foundational system of mathematics <span class="fragment highlight-blue"> not as a standard of consistency applied only
to establish a few fundamental theorems, but as a tool that can be employed in everyday
mathematical work.</span> &rdquo;</q></p>


<div style="float:right"> Vladimir Voevodsky</div>

	</section>

</section>


<section>
	<section>
		<h3> Martin-L&Oumlf Type theory</h3>
			<p> Type theoretic Foundations</p>
		 	<p>Terms, Types, Rules</p>
		 	<p>Inductive types</p>
		 	<p> Dependent Types</p>
		 	<p>Propositions as types</p>
	</section>
	<section>
		<h3>Higher-order languages</h3>
		<ul>
			<li class="fragment">A language has words and phrases belonging to various <em>syntactic categories</em>.</li>
			<li class="fragment">The grammar specifies rules for forming phrases from words and phrases, based on their syntactic categories.</li>
			<li class="fragment">First order logic is closely modelled on this, with terms analogues of noun phrases, functions and relations analogues of verbs and formulas analogues of sentential phrases.</li>
			<li class="fragment">However, meaningless but valid sentences are avoided by having no verb phrases other than the small number of verbs in the vocabulary.</li>
		</ul>
	</section>
	<section>
		<h3>Higher-order languages.</h3>
		<ul>
			<li class="fragment">In a higher order logic we have rules for forming new syntactic categories.</li>
			<li class="fragment">In a simple higher order language, these are formed from other syntactic categories (generics).</li>
			<li class="fragment"> In a <em>dependently typed</em> language, syntactic categories are regarded as words/phrases.
			<li class="fragment"> Thus, we can form syntactic categories in terms of words/phrases.</li>
			<li class="fragment"> We can also form phrases using syntactic categories.</li>
		</ul>
	</section>
	<section>
		<h3> Type theoretic foundations</h3>
		<ul>
			<li class="fragment"> A Type theory is a type system rich enough to replace
				Set theory as foundations for mathematics.</li>
			<li class="fragment"> Mathematical objects, called <em> terms</em>, have <em> types </em>. </li>
			<li class="fragment"> A term $a$ having a type $A$, denoted $a : A$, is analogous to
				an element $a$ belonging to a set $A$, i.e., $a \in A$.</li>
			<li class="fragment"> However the rules for forming terms and types, and for determining
				whether a term has a type, are purely <em class="fragment highlight-current-blue"> syntactic. </em></li>
			<li class="fragment"> Nevertheless, the rules for forming types are rich enough that types can play the role of sets
				<span class="fragment"> - for instance, prime numbers form a type.</span>
			 </li>
			<li class="fragment"> Even more remarkably, propositions and proofs can be expressed in terms of types and terms.
			</li>
		</ul>
	</section>

	<section>
	  <h3> Terms, Types, Rules </h3>
	  <ul>
	  <li class="fragment"> Mathematical objects are called <em>terms. </em> </li>
	  <li  class="fragment"> Every term has a <em> type </em>, generally unique.</li>
	  <li class="fragment"> Types are also terms, whose types are <em class="fragment highlight-current-blue"> universes</em>.</li>
		<li class="fragment"> We have <em>rules</em> to introduce terms (including types), individually or in groups, into the context.</li>
		<li class="fragment"> Rules also let us make two kinds of <strong>judgements</strong>:
	  	<ul>
				<li> that a term $a$  is of type $A$. </li>
				<li> that two terms are equal <em class="fragment highlight-current-blue"> by definition </em>.
				</ul>
			</li>
			<li class="fragment"> All the rules are syntactic.</em>
	    <li class="fragment">  Note that terms can be equal without being so by definition. </li>
	    <li class="fragment"> There is a relation (type family) <em class="fragment highlight-current-blue"> propositional equality</em> extending definitional equality.</li>
	  </ul>
	  </section>

	<section>
	  <h3> Function types, functions and applications </h3>
	  <ul>
	    <li class="fragment"> Given types $A$ and $B$, we can introduce the function type $A \to B$, whose members are functions.</li>
	    <li class="fragment"> Given $f: A \to B$ and $a : A$, we get a term $f(a) : B$.</li>
	    <div class="fragment">
	      <li> We can construct a function $f: A \to B$,
					$$f(a) := b,$$
					by giving an expression $b$ of type $B$
					in terms of a variable $a : A$ and other terms in the context.</li>
</div>
	    <li class="fragment"> We can also define functions <em> recursively</em> on
				<em class="fragment highlight-current-blue"> inductive types</em>.</li>
	    </ul>
	</section>


	<section>
	  <h3> Dependent functions and type families </h3>
	  <ul>
	    <li class="fragment"> We generalize functions $f : A \to B$ to <em class="fragment highlight-current-blue"> dependent functions</em>, so that $f(a)$ has a type $B(a)$, depending in general on $a : A$.</li>
	    <li class="fragment"> More precisely,
	      <ul>
		<li class="fragment"> A <em class="fragment highlight-current-blue"> type family</em> $B: A \to \mathfrak{U}$ is a function with codomain a universe, so all its values are types. </li>
		<li class="fragment"> Given a type family $B: A \to \mathfrak{U}$, we can construct a corresponding type $\prod_{a : A} B(a)$ of dependent functions.</li>
		<li class="fragment"> We can apply $f : \prod_{a : A} B(a)$ to $a : A$, to obtain $f(a) : B(a)$.</li>
		</ul>
	      </li>
	  <li class="fragment"> Constructions of dependent functions are analogous to those of functions.</li>
	  </ul>
	  </section>


	<section>
	  <h3>  Inductive types</h3>
	  <ul>
			<li class="fragment"> An inductive type $T$
				 is defined by specifying terms (usually functions)
				that construct members of $T$. </li>

<pre class="fragment"><code class="haskell">
data ℕ : Type where
  zero : ℕ
  succ : ℕ → ℕ
</code></pre>

	<li class="fragment"> Formally, we are introducing into the context the type $\mathbb{N}$ and two terms $0$ and $succ$.</li>
	<li class="fragment"> The type is <em class="fragment highlight-current-blue"> freely generated</em> by its constructors, allowing recursive
		and inductive definitions.</li>
	    </ul>
	  </section>

	<section>
	  <h3> Recursive definitions </h3>
	  <ul>
	    <li class="fragment"> We can define functions recursively on inductive types, by specifying in all cases.</li>

<div>
<pre class="fragment"><code class="haskell">
_+_ : ℕ → ℕ → ℕ
zero + y = y
(succ x) + y = succ (x + y)
	</code></pre>
</div>
<li class="fragment"> Formally, we can introduce recursion functions and apply them to the definition data. </li>
</ul>
	</section>



	<!-- <section>
	  <h3>Vectors : an inductive type family </h3>
	  <ul>
	    <li class="fragment"> We have a type family associating to each $n : \mathbb{N}$ the type of vectors of length $n$ with entries in a type $A$.</li>
	    <li class="fragment"> This is an inductive type family with two constructors.</li>
<div class="fragment">
<pre><code class="haskell">
data Vector (A : Type) : ℕ → Type where -- inductive type family
  [] : Vector A 0
  _::_ : {n : ℕ} → A → Vector n → Vector (succ n)
</code></pre>
</div>
	    <li class="fragment"> We can define dependent functions to a type family
				<em>inductively</em>.</li>
<div class="fragment">
<pre><code class="haskell">
countdown : (n : ℕ) → Vector ℕ n -- dependent function
countdown 0 = []
countdown (succ n) = (succ n) :: (countdown n)
</code></pre>
</div>
	    <li class="fragment"> Formally, we can construct an <em class="fragment highlight-current-blue">induction function</em> and apply it to the data.</li>
	  </ul>
	  </section>

	<section>
	  <h3> Functions on inductive type families </h3>
	  <ul>
	    <li class="fragment"> We can define (dependent) functions on inductive type families recursively (inductively).</li>
	    <li class="fragment"> However, we must define these simultaneously on all types in the inductive type family.</li>
<div class="fragment">
<pre><code class="haskell">
sum : {n : ℕ} → Vector ℕ n → ℕ
sum [] = 0
sum (x :: l) = x + sum l
</code></pre>
</div>
	  </ul>
	  </section> -->

		<section>
			<h3> More Inductive types</h3>
			<ul>
				<li class="fragment"> The types $\mathbb{0}$ has no terms .</li>
				<li class="fragment"> The type $\mathbb{1}$ has a single term $*$.</li>
				<li class="fragment"> The product type $A \times B$ has terms (corresponding to)
					pairs $(a, b)$ with $a: A$ and $b : B$.</li>
				<li class="fragment"> The sum (disjoint union) type $A \oplus B$ has terms (corresponding to) terms of $A$ and terms of $B$.</li>
				<li class="fragment"> For a type family $B: A \to \mathcal{U}$, the
					<em>dependent pair</em> type
					$\sum_{a: A} B(a)$ has terms (corresponding to) pairs $(a, b)$
					with $a: A$ and $b : B(a)$.</li>
		</section>


		<section>
			<h3>Propositions as types</h3>
			<ul>
				<li class="fragment">A type $A$ is <em>inhabited</em> if there is a term $a$ with $a : A$.</li>
				<li class="fragment">By <em> propostion</em> we mean a logical statement that must be true or false.</li>
				<li class="fragment">We represent propositions by types.</li>
				<li class="fragment">If a type $A$ is viewed as a proposition, a term $a : A$ is a <em class="fragment highlight-current-blue">proof</em> of (or witness to) $A$.
				<li class="fragment">In particular, a proposition is <strong>true</strong> if and only if the corresponding type is <strong>inhabited</strong>.</li>
				<li class="fragment">Note that we must be able to form types representing mathematical propositions by the type formation rules.</li>
			</ul>
		</section>

		<section>
			<h3>Combining propositions</h3>
			<p class="fragment"> Let $A$ and $B$ be types, regarded as representing propositions.</p>
			<ul>
				<li class="fragment"> The proposition $A \Rightarrow B$ is represented by $A \to B$.</li>
				<li class="fragment"> The propostion $A\wedge B$ is represented by $A \times B$.</li>
				<li class="fragment"> The proposition $A \vee B$ is represented by $A \oplus B$.</li>
				<li class="fragment"> The proposition $\neg A$ is represented by $A \to \mathbb{0}$.</li>
			</ul>
		</section>

		<section>
			<h3>Quantifying propositions</h3>
			<ul>
				<li class="fragment">A proposition depending on a variable $x : A$ is represented by a type family
					$P : A \to \mathfrak{U}$. </li>
				<li class="fragment">The proposition $\forall x\in A,\ P(x)$ is  $\prod_{x: A} P(x)$.</li>
				<li class="fragment">The proposition $\exists x\in A,\ P(x)$ is  $\sum_{x : A} P(x)$.</li>
			</ul>
		</section>

	<section>
	  <h3> Identity type family</h3>
	  <ul>
	    <li class="fragment"> For a fixed type $A$, propositional equality is given by the identity type family freely generated by reflexivity.</li>
<div class="fragment">
<pre><code class="haskell">
data _==_ {A : Type} : A → A → Type where
  refl : (a : A) → a == a
</code></pre>
</div>
	    <li class="fragment"> This is an inductive type family.</li>

<div class="fragment">
<pre><code class="haskell">
symmetry : {A : Type} → {x y : A} → (x == y) → (y == x)
symmetry (refl a) = refl a

trans : {A : Type} → {x y z : A} → (x == y) → (y == z) → (x == z)
trans (refl a) (refl .a) = refl a
</code></pre>
</div>
	    <li class="fragment"> However, for fixed $a: A$, $a = a$ is <strong> not </strong> an inductive type, i.e., it is not suffiicient to define functions on $refl(a)$.</li>
	  </ul>
	  </section>
</section>


<section>
	<section>
		<h3>Homotopy type theory: Types as Spaces</h3>
		<p> Equality, Paths, Homotopy </p>
		<p> Levels from dimension</p>
		<p> Sets, Propositions</p>
	</section>

	<section>
	  <h3> Types as Spaces </h3>
	  <ul>
	    <li class="fragment"> We <em class="fragment highlight-current-blue">interpret</em>
	      <ul>
		<li class="fragment"> Types as <em class="fragment highlight-blue">spaces</em>. </li>
		<li class="fragment"> Terms of a type as points of the space.</li>
		<li class="fragment"> Functions $A \to B$ as continuous functions $A \to B$.
		<li class="fragment"> For a type $A$ and terms $x, y: A$, the identity type $x = y$ as
			<em class="fragment highlight-blue">paths</em> in $A$ from $x$ to $y$.</li>
	      </ul></li>
	    <li class="fragment"> We do not actually construct spaces, i.e., sets with topology, starting with a type.</li>
	    <li class="fragment"> Instead we make topological (specifically homotopy theoretic) constructions and prove topological results in type theory.</li>
	    <li class="fragment"> A practical consequence for type theories is that we get a canonical, provably consistent, type theory.</li>
	  </ul>
	  </section>

	<section>
	  <h3> Equality, Paths,  Homotopies</h3>
	  <ul>
	    <li class="fragment"> As above, for a type $A$ and $x, y : A$, a term $p : (x = y)$ is interpreted
				as a path from $x$ to $y$.
			</li>
			<li class="fragment"> Two such paths are equal if there is a path of paths, called a homotopy,
				between them.
			</li>
			<img src="HomotopySmall.gif" class="fragment" height = "200"/>
			<img src="Mug_and_Torus_morph.gif" class="fragment" height="200" />
	    <li class="fragment"> We have similar notions of equality for functions.</li>
			<li class="fragment"> Types are equal if the corresponding spaces are homotopy equivalent,
				as a consequence of the <em> Univalence axiom. </em></li>
	  </section>


	<section>
	  <h3> Dimension and levels </h3>
	  <ul>
			<li class="fragment"> We define levels of types, based on a characterization of dimension in homotopy theory.</li>
	    <li class="fragment"> By definition, there is a unique type at level $-2$ (the lowest),
				which has a single term. </li>
	    <li class="fragment"> Inductively, we define the level of a type $A$ to be at most $(n + 1)$
				if for $a, b : X$, the type $a = b$ has level at most $n$.</li>
	    <li class="fragment"> Further, we can truncate a type canonically to an $n$-type.</li>
	    </ul>
	  </section>

	<section>
	  <h3> Sets and mere propositions </h3>
	  <ul>
	    <li class="fragment"> A set is a space with all of its components contractible.</li>
	    <li class="fragment"> A type $A$ is a set if for $x, y: A$ and $p, q: x = y$, we have $p = q$.</li>
	    <li class="fragment"> A mere proposition is a type which is either empty or all of its elements are equal,
				i.e., a type at level $-1$.</li>
	    <li class="fragment"> The concept of mere propostions, as well as propositional truncation,
				allow consistent mixing of classical logic with the type theoretic form.</li>
			<li class="fragment"> For instance, in homotopy type theory the law of excluded middle is usually assumed
				for mere propositions, but not for all types.</li>
	  </section>


		<!-- <section>
			<h3> Lean theorem prover </h3>
			<ul>
				<li class="fragment"> In a language like Agda, it is practical to write moderate sized proofs fully formally.</li>
				</li>
				<li class="fragment"> The lean theorem prover allows this, and also has an elaboration engine to help complete proofs efficiently.
				</li>
				<li class="fragment"> The proofs can be in homotopy type theory.</li>
					<li class="fragment"> Checking a (fully elaborated) proof is fairly easy, and lean has an efficient export format
						and an independent Haskell typechecker to do this.</li>
				<li class="fragment"> The export format, server and API also allow efficient integration with other systems.
				</li>
			</ul>
		</section> -->

</section>

<section>
	<section>
		<h3> Proving-Ground: Theorem proving by Learning</h3>
		<p> HoTT implemented in Scala </p>
		<p> Reinforcement learning </p>
		<p> Representation learning </p>
		<p> Natural language processing </p>
	</section>

	<section>
		<h3> Useful theorems and proofs </h3>
		<ul>
			<li class="fragment"> A theorem with a simple statement but difficult proof is useful.</li>
			<li class="fragment"> A theorem used to prove many other theorems is useful.</li>
			<li class="fragment"> Particularly for applications, we may have an externally determined
				notion of <em>a priori</em> usefulness.</li>
			<li class="fragment"> With homotopy type theory and backward propagation, all these
				can be naturally captured in simple learning dynamics.</li>
		</ul>
	</section>



	<section>
		<h3> Reinforcement learning: term-type map </h3>
		<ul>
			<li class="fragment"> Given an initial distribution $P_0$ on terms, rules for forming terms gives a new distribution
				which can be recursively defined by a relation of the form
					$$P = \alpha P_0 + \beta \mu_*(P) + \gamma \theta_*(P \times P) + \dots$$
				</li>
			<li class="fragment"> Given a probability distribution on terms
				 we get one on types by
				mapping a term to its type (proof distribution). </li>
			<li class="fragment"> As (inhabited) types themselves are terms, we get a restricted distribution on them
				(theorem distribution). </li>
			<li class="fragment"> We have a flow of the (entropy of) the proof distribution towards the theorem distribution.</li>
			<li class="fragment"> We can backward propagate to get a flow on the distribution on terms.</li>
			<li class="fragment"> The distribution on theorems can have other components.</li>
		</ul>

	</section>

	<section>
		<h3> Representation learning </h3>
		<p> Using proximity and order, words, mathematical objects etc can be represented by vectors
			which capture many of their relations.
		</p>
	</section>

	<section>
		<h3> NLP: extracting from human literature.</h3>
		<ul>
			<li class="fragment"> We aim to extract mathematical objects from the literature,
				with reasonably high accuracy. </li>
			<li class="fragment"> These can be used for learning, both giving terms from which to generate others,
				and a distribution on types.</li>
			<li class="fragment"> This is similar to a translation problem, except the target language has
				strong restrictions on sentences being meaningful and true.</li>
			<li class="fragment"> To extract from natural language, we first use a parser.</li>
			</ul>
		</section>

</section>


<section>
	<section>
		<h3> The Slice-Ribbon conjecture: </h3>
		<h3> Computer-assisted approaches </h3>
	</section>
	<section>
		<h3> Knots: Slice and Ribbon </h3>
		<ul>
			<li class="fragment"> A knot $K$ is a smoothly embbed circle in $S^3$.
			<img src="240px-Square_ribbon_knot.svg.png" />
			</li>
			<li class="fragment"> $K$ is <em>unknotted</em> if it bounds a smoothly embedded disc in $S^3$.</li>
			<li class="fragment"> $K$ is <em>slice</em> if it bounds a smoothly embedded disc in $B^4$.</li>
			<li class="fragment"> $K$ is <em>ribbon</em> if it bounds a slice disc
				so that $x^2+y^2+z^2$ has (no degenerate critical points and) no local maxima in it.</li>
			<li class="fragment"> The slice-ribbon conjecture says that evey slice knot is ribbon.</li>
		</ul>
	</section>
	<section>
		<h3> Workflow </h3>
		<ul>
			<li class="fragment"> We seek useful results by interaction, working out and the literature.</li>
			<li class="fragment"> Working out is a combination of experimentation, computation, deduction and search,
				with learning.</li>
			<li class="fragment"> We seek:
				<ul>
					<li class="fragment"> Consequences of being <em>ribbon</em> - to contradict.</li>
					<li class="fragment"> Constructions of <em>slice</em> knots.</li>
					<li class="fragment"> Modifications of, and relations between, slice discs for a fixed knot.</li>
					<li class="fragment"> Invariants, complexities etc associated to slice discs.</li>
				</ul>
			</li>
			<li class="fragment"> One may similarly analyse, for example, the mean curvature flow.</li>
		</ul>
	</section>

</section>

